import os
import yfinance as yf
from dotenv import load_dotenv
from typing import List, TypedDict, Annotated
import operator
import re

# LangChain & Groq
from langchain_groq import ChatGroq
from langchain_core.tools import tool
from langchain_core.messages import HumanMessage, SystemMessage, AIMessage, BaseMessage
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_community.tools.tavily_search import TavilySearchResults

# LangGraph
from langgraph.graph import StateGraph, START, END
from langgraph.prebuilt import ToolNode
from langgraph.checkpoint.memory import MemorySaver

load_dotenv()

# ==========================================
# 0. å®šç¾© Deep Agent ç‹€æ…‹ (æ ¸å¿ƒå‡ç´š)
# ==========================================
class DeepAgentState(TypedDict):
    messages: Annotated[List[BaseMessage], operator.add]
    tasks: List[str]            # å¾…åŸ·è¡Œçš„å­ä»»å‹™æ¸…å–®
    completed_tasks: Annotated[List[str], operator.add]  # å·²å®Œæˆçš„ä»»å‹™ï¼ˆä½¿ç”¨ operator.add è¿½åŠ ï¼‰
    research_notes: Annotated[List[str], operator.add]   # å„²å­˜æ¯ä¸€è¼ªæœå°‹åˆ°çš„æ·±åº¦å…§å®¹ï¼ˆä½¿ç”¨ operator.add è¿½åŠ ï¼‰
    iteration: int              # è¿½è¹¤è¿­ä»£æ¬¡æ•¸ï¼Œé˜²æ­¢ç„¡é™å¾ªç’°
    query: str                  # åŸå§‹å•é¡Œ

# ==========================================
# 1. åˆå§‹åŒ–èˆ‡å·¥å…· (ä¿ç•™ä¸¦å¼·åŒ–æ‚¨çš„å·¥å…·)
# ==========================================
def get_llm():
    return ChatGroq(
        model=os.getenv("GROQ_MODEL", "llama-3.3-70b-versatile"),
        temperature=0.1,
        max_retries=2,
    )

@tool
def get_company_deep_info(ticker: str) -> str:
    """æŸ¥è©¢è‚¡ç¥¨çš„è©³ç´°ç‡Ÿé‹ç‹€æ³ï¼ŒåŒ…æ‹¬ç¾åƒ¹ã€å¸‚å€¼ã€æœ¬ç›Šæ¯”ã€ç‡Ÿæ”¶å¢é•·ç­‰æ·±åº¦æ•¸æ“šã€‚"""
    try:
        stock = yf.Ticker(ticker)
        info = stock.info
        summary = (
            f"è‚¡ç¥¨: {info.get('longName')} ({ticker})\n"
            f"ç¾åƒ¹: {info.get('currentPrice')} {info.get('currency')}\n"
            f"å¸‚å€¼: {info.get('marketCap')}\n"
            f"æœ¬ç›Šæ¯” (PE): {info.get('trailingPE')}\n"
            f"ç‡Ÿæ”¶å¢é•·: {info.get('revenueGrowth')}\n"
            f"æ¥­å‹™æ‘˜è¦: {info.get('longBusinessSummary')[:500]}..."
        )
        return summary
    except Exception as e:
        return f"æ•¸æ“šæŸ¥è©¢å¤±æ•—: {e}"

@tool
def search_web(query: str) -> str:
    """æœå°‹ç¶²éš›ç¶²è·¯ä»¥ç²å–æœ€æ–°æ–°èæˆ–ä¸€èˆ¬çŸ¥è­˜ã€‚"""
    try:
        tool = TavilySearchResults(k=5) # å¢åŠ æœå°‹é‡ä»¥ç²å–æ·±åº¦è³‡è¨Š
        return str(tool.invoke(query))
    except Exception as e:
        return f"æœå°‹éŒ¯èª¤: {e}"

tools_list = [get_company_deep_info, search_web]
llm = get_llm()
llm_with_tools = llm.bind_tools(tools_list)

# ==========================================
# 2. Deep Agent ç¯€é»é‚è¼¯
# ==========================================

def planner_node(state: DeepAgentState):
    """è¦åŠƒç¯€é»ï¼šå°‡è¤‡é›œå•é¡Œæ‹†è§£ç‚ºå…·é«”çš„ç ”ç©¶è¨ˆç•«"""
    try:
        prompt = ChatPromptTemplate.from_template(
            "ä½ æ˜¯ä¸€å€‹è³‡æ·±ç ”ç©¶è¦åŠƒå“¡ã€‚è«‹é‡å°ç”¨æˆ¶çš„å•é¡Œï¼š'{query}'\n"
            "æ‹†è§£å‡º 3-5 å€‹å…·é«”çš„ç ”ç©¶æ­¥é©Ÿï¼Œä¾‹å¦‚ï¼š\n"
            "1. æŸ¥è©¢åŸºç¤è²¡å ±æ•¸æ“š\n"
            "2. æœå°‹è¿‘æœŸé‡å¤§æ–°è\n"
            "3. åˆ†æç”¢æ¥­ç«¶çˆ­åŠ›\n"
            "è«‹åªè¼¸å‡ºæ¸…å–®ï¼Œæ¯è¡Œä¸€å€‹ä»»å‹™ï¼Œæ ¼å¼ç‚ºï¼šæ•¸å­—. ä»»å‹™æè¿°"
        )
        chain = prompt | llm | StrOutputParser()
        result = chain.invoke({"query": state["query"]})
        
        # æ›´å¥å£¯çš„ä»»å‹™è§£æï¼šæå–æ•¸å­—é–‹é ­æˆ–åˆ—è¡¨é …
        tasks = []
        for line in result.split("\n"):
            line = line.strip()
            if not line:
                continue
            # ç§»é™¤ç·¨è™Ÿï¼ˆå¦‚ "1. " æˆ– "- "ï¼‰
            cleaned = re.sub(r'^[\d\-â€¢]\s*\.?\s*', '', line)
            if cleaned:
                tasks.append(cleaned)
        
        # å¦‚æœè§£æå¤±æ•—ï¼Œä½¿ç”¨å‚™ç”¨æ–¹æ¡ˆ
        if not tasks:
            tasks = [
                "æŸ¥è©¢åŸºç¤è²¡å‹™æ•¸æ“šå’Œç‡Ÿé‹ç‹€æ³",
                "æœå°‹è¿‘æœŸé‡å¤§æ–°èå’Œå¸‚å ´å‹•æ…‹",
                "åˆ†æç”¢æ¥­ç«¶çˆ­åŠ›å’Œæœªä¾†å‰æ™¯"
            ]
        
        print(f"   ğŸ“ [Planner] ç”Ÿæˆè¨ˆç•«: {tasks}")
        return {
            "tasks": tasks, 
            "completed_tasks": [], 
            "research_notes": [],
            "iteration": 0
        }
    except Exception as e:
        print(f"   âš ï¸ [Planner] è¦åŠƒå¤±æ•—: {e}ï¼Œä½¿ç”¨é è¨­è¨ˆç•«")
        default_tasks = [
            "æŸ¥è©¢åŸºç¤è²¡å‹™æ•¸æ“šå’Œç‡Ÿé‹ç‹€æ³",
            "æœå°‹è¿‘æœŸé‡å¤§æ–°èå’Œå¸‚å ´å‹•æ…‹",
            "åˆ†æç”¢æ¥­ç«¶çˆ­åŠ›å’Œæœªä¾†å‰æ™¯"
        ]
        return {
            "tasks": default_tasks,
            "completed_tasks": [],
            "research_notes": [],
            "iteration": 0
        }

def research_agent_node(state: DeepAgentState):
    """åŸ·è¡Œç¯€é»ï¼šæ ¹æ“šç›®å‰çš„ä»»å‹™æ¸…å–®ï¼Œä½¿ç”¨å·¥å…·é€²è¡Œæ·±åº¦ç ”ç©¶"""
    # æª¢æŸ¥è¿­ä»£æ¬¡æ•¸ï¼Œé˜²æ­¢ç„¡é™å¾ªç’°
    max_iterations = 5
    current_iteration = state.get("iteration", 0)
    if current_iteration >= max_iterations:
        return {"messages": [AIMessage(content="å·²é”æœ€å¤§è¿­ä»£æ¬¡æ•¸ï¼Œåœæ­¢ç ”ç©¶ã€‚")]}
    
    current_task_idx = len(state.get("completed_tasks", []))
    tasks = state.get("tasks", [])
    
    if current_task_idx >= len(tasks):
        return {"messages": [AIMessage(content="æ‰€æœ‰ç ”ç©¶ä»»å‹™å·²å®Œæˆã€‚")]}
    
    current_task = tasks[current_task_idx]
    print(f"   ğŸ•µï¸ [Researcher] æ­£åœ¨åŸ·è¡Œä»»å‹™ {current_task_idx + 1}/{len(tasks)}: {current_task}")
    
    try:
        system_msg = SystemMessage(content=(
            f"ä½ æ˜¯ä¸€ä½æ·±åº¦ç ”ç©¶å“¡ã€‚ç•¶å‰ç›®æ¨™ä»»å‹™æ˜¯ï¼š{current_task}\n"
            f"è«‹ä½¿ç”¨å·¥å…·ç²å–è©³ç´°è³‡è¨Šã€‚ä½ å¯ä»¥é€²è¡Œå¤šè¼ªå·¥å…·èª¿ç”¨ä¾†æ·±å…¥æŒ–æ˜è³‡è¨Šã€‚\n"
            f"ç•¶ä½ èªç‚ºè³‡è¨Šå·²ç¶“è¶³å¤ æ™‚ï¼Œè«‹ç¸½çµä½ çš„ç™¼ç¾ä¸¦å›è¦†ã€‚"
        ))
        
        # æ§‹å»ºä¸Šä¸‹æ–‡ï¼šåŒ…å«åŸå§‹å•é¡Œã€å·²å®Œæˆä»»å‹™å’Œç ”ç©¶ç­†è¨˜
        context_messages = [system_msg]
        
        # å¦‚æœæœ‰ç ”ç©¶ç­†è¨˜ï¼ŒåŠ å…¥ä¸Šä¸‹æ–‡
        if state.get("research_notes"):
            notes_summary = "\n".join(state["research_notes"][-3:])  # åªå–æœ€è¿‘3æ¢ç­†è¨˜
            context_messages.append(SystemMessage(
                content=f"å…ˆå‰çš„ç ”ç©¶ç™¼ç¾ï¼š\n{notes_summary}"
            ))
        
        # åŠ å…¥æ­·å²æ¶ˆæ¯
        context_messages.extend(state["messages"][-10:])  # åªä¿ç•™æœ€è¿‘10æ¢æ¶ˆæ¯é¿å…ä¸Šä¸‹æ–‡éé•·
        
        response = llm_with_tools.invoke(context_messages)
        return {
            "messages": [response],
            "iteration": current_iteration + 1
        }
    except Exception as e:
        print(f"   âš ï¸ [Researcher] ç ”ç©¶å¤±æ•—: {e}")
        error_msg = AIMessage(content=f"ç ”ç©¶éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
        return {
            "messages": [error_msg],
            "iteration": current_iteration + 1
        }

def note_taking_node(state: DeepAgentState):
    """ç´€éŒ„ç¯€é»ï¼šå°‡ç ”ç©¶çµæœè½‰åŒ–ç‚ºç­†è¨˜ï¼Œå­˜å…¥ research_notes ç·©å­˜"""
    try:
        last_msg = state["messages"][-1]
        completed_count = len(state.get("completed_tasks", []))
        tasks = state.get("tasks", [])
        
        if completed_count >= len(tasks):
            return {}
        
        current_task = tasks[completed_count]
        
        # ä½¿ç”¨ LLM æ‘˜è¦ç ”ç©¶çµæœï¼Œæå–é—œéµè³‡è¨Š
        try:
            summary_prompt = ChatPromptTemplate.from_template(
                "è«‹å°‡ä»¥ä¸‹ç ”ç©¶çµæœæ‘˜è¦ç‚º3-5å€‹é—œéµè¦é»ï¼š\n\n{content}\n\n"
                "è«‹ä»¥ç°¡æ½”çš„æ¢åˆ—å¼å‘ˆç¾ã€‚"
            )
            chain = summary_prompt | llm | StrOutputParser()
            summary = chain.invoke({"content": last_msg.content})
        except:
            # å¦‚æœæ‘˜è¦å¤±æ•—ï¼Œç›´æ¥ä½¿ç”¨åŸå§‹å…§å®¹
            summary = last_msg.content[:500] + "..." if len(last_msg.content) > 500 else last_msg.content
        
        note = f"ã€ä»»å‹™ {completed_count + 1}: {current_task}ã€‘\n{summary}\n"
        print(f"   ğŸ“Œ [NoteTaker] å·²ç´€éŒ„ä»»å‹™ {completed_count + 1} çš„ç ”ç©¶ç­†è¨˜ã€‚")
        
        # æ³¨æ„ï¼šç”±æ–¼ä½¿ç”¨äº† operator.addï¼Œé€™è£¡è¿”å›çš„åˆ—è¡¨æœƒè¢«è¿½åŠ åˆ°ç¾æœ‰åˆ—è¡¨
        return {
            "research_notes": [note], 
            "completed_tasks": [current_task]
        }
    except Exception as e:
        print(f"   âš ï¸ [NoteTaker] è¨˜éŒ„å¤±æ•—: {e}")
        return {}

def final_report_node(state: DeepAgentState):
    """ç¸½çµç¯€é»ï¼šå°‡æ‰€æœ‰ç ”ç©¶ç­†è¨˜å½™æ•´æˆæœ€çµ‚å ±å‘Š (é€™å°±æ˜¯ Deep Agent çš„æœ€çµ‚ç”¢å‡º)"""
    try:
        research_notes = state.get("research_notes", [])
        if not research_notes:
            return {"messages": [AIMessage(content="æœªæ”¶é›†åˆ°è¶³å¤ çš„ç ”ç©¶è³‡æ–™ï¼Œç„¡æ³•ç”Ÿæˆå ±å‘Šã€‚")]}
        
        all_notes = "\n\n".join(research_notes)
        completed_tasks = state.get("completed_tasks", [])
        
        prompt = ChatPromptTemplate.from_template(
            "ä½ æ˜¯ä¸€ä½å°ˆæ¥­åˆ†æå¸«ã€‚è«‹æ ¹æ“šä»¥ä¸‹æ”¶é›†åˆ°çš„ç ”ç©¶ç­†è¨˜ï¼Œç‚ºç”¨æˆ¶å•é¡Œ '{query}' æ’°å¯«ä¸€ä»½çµæ§‹å®Œæ•´çš„æ·±åº¦å ±å‘Šã€‚\n\n"
            "å·²å®Œæˆçš„ç ”ç©¶ä»»å‹™ï¼š\n{completed_tasks}\n\n"
            "ç ”ç©¶ç­†è¨˜å…§å®¹ï¼š\n{notes}\n\n"
            "è«‹æ’°å¯«ä¸€ä»½å°ˆæ¥­å ±å‘Šï¼ŒåŒ…å«ä»¥ä¸‹éƒ¨åˆ†ï¼š\n"
            "1. åŸ·è¡Œæ‘˜è¦ï¼ˆExecutive Summaryï¼‰\n"
            "2. æ•¸æ“šåˆ†æèˆ‡è²¡å‹™ç‹€æ³\n"
            "3. è¿‘æœŸå‹•æ…‹èˆ‡å¸‚å ´è¡¨ç¾\n"
            "4. ç”¢æ¥­ç«¶çˆ­åŠ›åˆ†æ\n"
            "5. æŠ•è³‡é¢¨éšªè©•ä¼°\n"
            "6. çµè«–èˆ‡å»ºè­°\n\n"
            "è«‹ç¢ºä¿å ±å‘Šå…§å®¹è©³å¯¦ã€é‚è¼¯æ¸…æ™°ï¼Œä¸¦åŸºæ–¼å¯¦éš›æ”¶é›†åˆ°çš„æ•¸æ“šã€‚"
        )
        chain = prompt | llm | StrOutputParser()
        report = chain.invoke({
            "query": state["query"], 
            "notes": all_notes,
            "completed_tasks": "\n".join([f"- {task}" for task in completed_tasks])
        })
        print(f"   ğŸ“Š [FinalReport] å ±å‘Šç”Ÿæˆå®Œæˆ")
        return {"messages": [AIMessage(content=report)]}
    except Exception as e:
        print(f"   âš ï¸ [FinalReport] å ±å‘Šç”Ÿæˆå¤±æ•—: {e}")
        return {"messages": [AIMessage(content=f"å ±å‘Šç”Ÿæˆéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {str(e)}")]}

# ==========================================
# 3. æ¢ä»¶è·¯ç”±
# ==========================================

def route_after_agent(state: DeepAgentState):
    """æ±ºå®šæ˜¯è¦å‘¼å«å·¥å…·ï¼Œé‚„æ˜¯é€²å…¥ç­†è¨˜éšæ®µ"""
    last_msg = state["messages"][-1]
    # æª¢æŸ¥æ˜¯å¦æœ‰å·¥å…·èª¿ç”¨
    if hasattr(last_msg, 'tool_calls') and last_msg.tool_calls:
        return "tools"
    # æª¢æŸ¥æ˜¯å¦é”åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•¸
    if state.get("iteration", 0) >= 20:
        return "note_taking"
    return "note_taking"

def route_after_note(state: DeepAgentState):
    """æ±ºå®šæ˜¯å¦é‚„æœ‰ä¸‹ä¸€å€‹ä»»å‹™è¦è·‘"""
    if len(state["completed_tasks"]) < len(state["tasks"]):
        return "research_agent"
    return "final_report"

# ==========================================
# 4. æ§‹å»º Deep Agent åœ–è¡¨
# ==========================================
builder = StateGraph(DeepAgentState)

builder.add_node("planner", planner_node)
builder.add_node("research_agent", research_agent_node)
builder.add_node("tools", ToolNode(tools_list))
builder.add_node("note_taking", note_taking_node)
builder.add_node("final_report", final_report_node)

builder.add_edge(START, "planner")
builder.add_edge("planner", "research_agent")

builder.add_conditional_edges(
    "research_agent",
    route_after_agent,
    {"tools": "tools", "note_taking": "note_taking"}
)
builder.add_edge("tools", "research_agent")

builder.add_conditional_edges(
    "note_taking",
    route_after_note,
    {"research_agent": "research_agent", "final_report": "final_report"}
)
builder.add_edge("final_report", END)

graph = builder.compile(checkpointer=MemorySaver())

# ==========================================
# 5. åŸ·è¡Œ
# ==========================================
def main():
    print("\nğŸš€ Deep Research Agent (Groq Edition) å•Ÿå‹•ï¼")
    config = {"configurable": {"thread_id": "deep-research-001"}}
    
    user_input = "æ¯”è¼ƒå¾®è»Ÿ(MSFT)å’Œè°·æ­Œ(GOOGL)åœ¨AIé ˜åŸŸçš„ä½ˆå±€ï¼ŒåŒ…æ‹¬è²¡å‹™æŠ•å…¥ã€æŠ€è¡“ç™¼å±•ã€å¸‚å ´ç­–ç•¥å’ŒæŠ•è³‡åƒ¹å€¼"
    
    print(f"User: {user_input}\n")
    
    # åˆå§‹åŒ–å®Œæ•´ç‹€æ…‹
    initial_state = {
        "query": user_input,
        "messages": [HumanMessage(content=user_input)],
        "tasks": [],
        "completed_tasks": [],
        "research_notes": [],
        "iteration": 0
    }
    
    events = graph.stream(
        initial_state,
        config,
        stream_mode="updates"
    )
    
    for event in events:
        for node, data in event.items():
            if node == "final_report":
                print(f"\n===== æœ€çµ‚æ·±åº¦å ±å‘Š =====\n{data['messages'][-1].content}")

if __name__ == "__main__":
    main()